{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from time import time\n",
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.227000678221465\n",
      "[ -3.96028505  -2.6710249  -11.37169165  -8.96719343 -18.9415048\n",
      " -15.26634796]\n",
      "[-5.03009863 -6.18305864 -7.34200192 -4.20625956 -0.82035628 -6.33256738\n",
      " -7.73883041 -9.13509107 -5.18018263 -1.01175158]\n",
      "[ -3.96028505  -2.6710249  -11.37169165  -8.96719343 -18.9415048\n",
      " -15.26634796  -5.03009863  -6.18305864  -7.34200192  -4.20625956\n",
      "  -0.82035628  -6.33256738  -7.73883041  -9.13509107  -5.18018263\n",
      "  -1.01175158]\n"
     ]
    }
   ],
   "source": [
    "V = np.array([\n",
    "    [1, 2, 3,2,1],  # Usuario 1\n",
    "    [4, 5, 6,3,1],  # Usuario 2\n",
    "    [7, 8, 9,4,1],\n",
    "        # Usuario 3\n",
    "\n",
    "])\n",
    "num_users, num_movies = V.shape\n",
    "num_features = 2  # Número de características latentes\n",
    "\n",
    "# Inicializar W y H aleatoriamente\n",
    "np.random.seed(0)\n",
    "Winit = np.random.rand(num_users, num_features)\n",
    "Hinit = np.random.rand(num_features, num_movies)\n",
    "\n",
    "W = Winit\n",
    "H = Hinit\n",
    "\n",
    "gradW = np.dot(W, np.dot(H, H.T)) - np.dot(V, H.T)\n",
    "gradH = np.dot(W.T, np.dot(W, H)) - np.dot(W.T, V)\n",
    "initgrad = norm(np.r_[gradW, gradH.T])\n",
    "gradW[np.logical_or(gradW < 0, W > 0)]\n",
    "gradH[np.logical_or(gradH < 0, H > 0)]\n",
    "projnorm = norm(np.r_[gradW[np.logical_or(gradW < 0, W > 0)],\n",
    "                              gradH[np.logical_or(gradH < 0, H > 0)]])\n",
    "print(projnorm)\n",
    "np.r_[gradW[np.logical_or(gradW < 0, W > 0)],\n",
    "                              gradH[np.logical_or(gradH < 0, H > 0)]]\n",
    "print(gradW[np.logical_or(gradW < 0, W > 0)])\n",
    "print(gradH[np.logical_or(gradH < 0, H > 0)])\n",
    "print(np.r_[gradW[np.logical_or(gradW < 0, W > 0)],\n",
    "                              gradH[np.logical_or(gradH < 0, H > 0)]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmf(V, Winit, Hinit, tol, maxiter):\n",
    "    \"\"\"\n",
    "    Perform Non-negative Matrix Factorization (NMF) using projected gradients.\n",
    "\n",
    "    Parameters:\n",
    "    V : numpy.ndarray\n",
    "        Input matrix to factor.\n",
    "    Winit : numpy.ndarray\n",
    "        Initial factor matrix W.\n",
    "    Hinit : numpy.ndarray\n",
    "        Initial factor matrix H.\n",
    "    tol : float\n",
    "        Tolerance for the stopping condition.\n",
    "    timelimit : float\n",
    "        Time limit for the computation.\n",
    "    maxiter : int\n",
    "        Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    W : numpy.ndarray\n",
    "        Factor matrix W after NMF.\n",
    "    H : numpy.ndarray\n",
    "        Factor matrix H after NMF.\n",
    "    \"\"\"\n",
    "    W = Winit\n",
    "    H = Hinit\n",
    "    initt = time()\n",
    "\n",
    "    gradW = np.dot(W, np.dot(H, H.T)) - np.dot(V, H.T)\n",
    "    gradH = np.dot(W.T, np.dot(W, H)) - np.dot(W.T, V)\n",
    "    initgrad = norm(np.r_[gradW, gradH.T])\n",
    "    print('Init gradient norm %f' % initgrad)\n",
    "\n",
    "    tolW = max(0.001, tol) * initgrad\n",
    "    tolH = tolW\n",
    "\n",
    "    for iter in range(1, maxiter):\n",
    "        # Stopping condition\n",
    "        projnorm = norm(np.r_[gradW[np.logical_or(gradW < 0, W > 0)],\n",
    "                             gradH[np.logical_or(gradH < 0, H > 0)]])\n",
    "        if projnorm < tol * initgrad :\n",
    "            break\n",
    "\n",
    "        (W, gradW, iterW) = nlssubprob(V.T, H.T, W.T, tolW, 1000)\n",
    "        W = W.T\n",
    "        gradW = gradW.T\n",
    "\n",
    "        if iterW == 1:\n",
    "            tolW = 0.1 * tolW\n",
    "\n",
    "        (H, gradH, iterH) = nlssubprob(V, W, H, tolH, 1000)\n",
    "        if iterH == 1:\n",
    "            tolH = 0.1 * tolH\n",
    "\n",
    "        if iter % 10 == 0:\n",
    "            stdout.write('.')\n",
    "\n",
    "    print('\\nIter = %d Final proj-grad norm %f' % (iter, projnorm))\n",
    "    return (W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlssubprob(V, W, Hinit, tol, maxiter):\n",
    "    \"\"\"\n",
    "    Solve the non-negative least squares subproblem.\n",
    "\n",
    "    Parameters:\n",
    "    V : numpy.ndarray\n",
    "        Constant matrix.\n",
    "    W : numpy.ndarray\n",
    "        Constant matrix.\n",
    "    Hinit : numpy.ndarray\n",
    "        Initial solution matrix H.\n",
    "    tol : float\n",
    "        Stopping tolerance.\n",
    "    maxiter : int\n",
    "        Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    H : numpy.ndarray\n",
    "        Updated solution matrix H.\n",
    "    grad : numpy.ndarray\n",
    "        Gradient of the objective function.\n",
    "    iter : int\n",
    "        Number of iterations used.\n",
    "    \"\"\"\n",
    "    H = Hinit\n",
    "    WtV = np.dot(W.T, V)\n",
    "    WtW = np.dot(W.T, W)\n",
    "\n",
    "    alpha = 1 #incial size\n",
    "    beta = 0.1 #controla el ajuste de alpha\n",
    "    for iter in range(1, maxiter):\n",
    "        grad = np.dot(WtW, H) - WtV\n",
    "        projgrad = norm(grad[np.logical_or(grad < 0, H > 0)])\n",
    "        if projgrad < tol:\n",
    "            break\n",
    "\n",
    "        # Search for step size\n",
    "        for inner_iter in range(1, 20):\n",
    "            Hn = H - alpha * grad\n",
    "            Hn = np.where(Hn > 0, Hn, 0)\n",
    "            d = Hn - H\n",
    "            gradd = np.sum(grad * d)\n",
    "            dQd = np.sum(np.dot(WtW, d) * d)\n",
    "            suff_decr = 0.99 * gradd + 0.5 * dQd < 0\n",
    "            \n",
    "            if inner_iter == 1:\n",
    "                decr_alpha = not suff_decr\n",
    "                Hp = H\n",
    "            \n",
    "            if decr_alpha:\n",
    "                if suff_decr:\n",
    "                    H = Hn\n",
    "                    break\n",
    "                else:\n",
    "                    alpha = alpha * beta\n",
    "            else:\n",
    "                if not suff_decr or np.all(Hp == Hn):\n",
    "                    H = Hp\n",
    "                    break\n",
    "                else:\n",
    "                    alpha = alpha / beta\n",
    "                    Hp = Hn\n",
    "\n",
    "    if iter == maxiter:\n",
    "        print('Max_iter reached')\n",
    "    \n",
    "    return (H, grad, iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([\n",
    "    [5, 0, 3, 0, 4],  # Usuario 1\n",
    "    [1, 1, 0, 0, 0],  # Usuario 2\n",
    "    [0, 5, 1, 0, 0],  # Usuario 3\n",
    "    [0, 5, 5, 0, 4],  # Usuario 4\n",
    "    [4, 5, 3, 0, 2],  # Usuario 5\n",
    "    [1, 0, 5, 0, 0],  # Usuario 6\n",
    "    [4, 3, 0, 0, 5]   # Usuario 7\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init gradient norm 27.047931\n",
      "\n",
      "Iter = 10 Final proj-grad norm 0.003434\n"
     ]
    }
   ],
   "source": [
    "num_users, num_movies = v.shape\n",
    "num_features = 5  # Número de características latentes\n",
    "\n",
    "# Inicializar W y H aleatoriamente\n",
    "np.random.seed(0)\n",
    "Winit = np.random.rand(num_users, num_features)\n",
    "Hinit = np.random.rand(num_features, num_movies)\n",
    "\n",
    "tol = 0.001\n",
    "maxiter = 100   # Máximo de iteraciones\n",
    "\n",
    "(wo, ho) = nmf(v, Winit, Hinit, tol, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "[[0.         0.         4.67962614 2.17279207 0.        ]\n",
      " [0.         0.         0.55157786 0.08979478 0.69991414]\n",
      " [0.         0.12409943 0.         0.59648708 3.44727642]\n",
      " [0.         5.75018596 0.         0.32487042 2.03825948]\n",
      " [0.         0.         2.91763834 2.26272117 3.48309367]\n",
      " [0.         0.0992832  0.         3.49362342 0.        ]\n",
      " [0.         0.47458177 4.92236678 0.         1.96179916]]\n"
     ]
    }
   ],
   "source": [
    "print('W')\n",
    "print(wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "[[6.17635497e-01 6.12095723e-01 6.16933997e-01 9.43748079e-01\n",
      "  6.81820299e-01]\n",
      " [0.00000000e+00 3.60318690e-01 7.86459218e-01 0.00000000e+00\n",
      "  7.00949830e-01]\n",
      " [8.85423564e-01 7.00714629e-04 0.00000000e+00 0.00000000e+00\n",
      "  8.65007566e-01]\n",
      " [3.73439384e-01 0.00000000e+00 1.38545645e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [1.87015709e-02 1.43659180e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('H')\n",
    "print(ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix aprox\n",
      "[[4.95485739e+00 3.27908250e-03 3.01030878e+00 0.00000000e+00\n",
      "  4.04791202e+00]\n",
      " [5.35002431e-01 1.00587741e+00 1.24406753e-01 0.00000000e+00\n",
      "  4.77119018e-01]\n",
      " [2.87221253e-01 4.99704440e+00 9.24006009e-01 0.00000000e+00\n",
      "  8.69874711e-02]\n",
      " [1.59438064e-01 5.00004634e+00 4.97238057e+00 0.00000000e+00\n",
      "  4.03059187e+00]\n",
      " [3.49347426e+00 5.00582825e+00 3.13490163e+00 0.00000000e+00\n",
      "  2.52377923e+00]\n",
      " [1.30465658e+00 3.57735911e-02 4.91834527e+00 0.00000000e+00\n",
      "  6.95925393e-02]\n",
      " [4.39506826e+00 2.99275445e+00 3.73239211e-01 0.00000000e+00\n",
      "  4.59054252e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix aprox\")\n",
    "print(np.dot(wo, ho))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
